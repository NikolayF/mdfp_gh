# Процесс разработки сервиса машинного обучения по теме "Обнаружение мошеннических транзакций (Fraud Detection)"

## 1. Бизнес-анализ (Business Understanding)

*   **Организационная структура:** Кто участвует в проекте со стороны заказчика сервиса, кто будет основным пользователем?
    *   На текущий момент конкретного заказчика нет, но данное решение может быть переиспользованно разнообразными компаниями
        *   **Текущий состав разработки:**
            *   Филимонов Николай
        *   **Основные пользователи:** 
            *   Клиенты банков и финансовых организаций
            *   Аналитики по борьбе с мошенничеством
            *   Службы безопасности и финансового мониторинга

*   **Собираем контакты, создаем рабочие чаты.**
    *   В правильном исполнении, этот процесс можно было бы описать так: Собираются контакты всех участников (ФИО, должность, email, телефон). Создается канал в Telegram или "Пачке" для оперативной коммуникации. Если есть возможность вести процесс в таск трекере, на подобие Jira, то весь рабочий процесс отображаем в нём.
*   **Какова бизнес-цель проекта?**
    *   Снижение финансовых потерь от мошеннических транзакций и повышение уровня безопасности транзакций, обрабатываемых компанией. Тем самым, повышение уровня доверия к самой компании и увеличение количества клиентов. Конкретные цели:
        *   Снижение количества мошеннических транзакций
        *   Снижение затрат на расследование мошеннических транзакций
        *   Уменьшение количества ошибочно заблокированных транзакций
*   **Существуют ли какие-то уже разработанные решения? Если существуют, то какие и чем именно текущее решение не устраивает?**
    
    *   **Существующие решения:** Некоторые организации используют правила на основе эвристики, "чёрный"/"белый" спикок и ручную проверку подозрительных транзакций. Так же могут использовать простые системы мониторинга транзакций и обрабатывать большую часть руками.
    *   **Недостатки:**
        *   Эвристические правила часто не учитывают сложные мошеннические схемы
        *   "чёрный"/"белый" списки могут быть легко взломаны и пройдены мошенниками
        *   Ручная проверка требует много времени и ресурсов
        *   Системы мониторинга могут давать слишком много ложных тревог и требуют большого погружения в анализ этих данных
        *   Недостаточная скорость обнаружения мошенничества, которое приведёт к оттоку клиентов из-за потери финансов, а методы пресечения не автоматизированны

### 1.1 Текущая ситуация (Assessing current solution)

*   **Оцениваем, хватает ли ресурсов для проекта.**

    *   На данный момент есть только 1 разработчик
    *   Доступ к данным или датасетам будет взят из открытых источников

*   **Есть ли доступное железо или его необходимо закупать?**
    *   Вычислительные ресурсы ограничены локальной машиной, а для обучения на GPU будет использоваться Kaggle, с возможностью обучения до 30 часов в неделю
    
*   **Где и как хранятся данные, будет ли предоставлен доступ в эти системы, нужно ли дополнительно докупать/собирать внешние данные?**

    *   **Источники данных:**
        *   Для решения данной задачи будут использоваться уже готовые датасеты (выбор итогового будет принят в процессе разработки), описанние в прошлом пункте должно хватить для реализации этих целей. Оба датасета представленны на Kaggle:
            
            *   IEEE-CIS Fraud Detection - https://www.kaggle.com/datasets/phambacong/ieee-cis-fraud-detection

                Описание: Большое количество признаков, включая как числовые, так и категориальные. Содержит большое количество данных, которые можно анализировать и интерпретировать

            *   Credit Card Fraud Detection - https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

                Описание: Анонимизирован (все признаки, кроме Time и Amount, являются результатом PCA преобразования). Но датасет сильно несбалансирован

    *   **Хранение:** Данные для обучения и анализа могут храниться в SQL-базах данных, но так же можно оставить их в формате-источнике CSV и использовать только на время обучения или анализа
    *   **Доступ:** Сырые данные находятся в свободном доступе, если использовать ресурс Kaggle, посде feature ingeenering они уже могут быть в бд или других файлах, к которым доступ нужно запрашивать у разработчика
    *   **Внешние данные:** Дообогащение внешними данными в этом проекте возможно, но изначально предполагается, что фичи можно будет извлекать из указанных датасетов
*   **Сможет ли заказчик выделить своих экспертов для консультаций на данный проект?**
    
    *   В данном проекте используется только разработка одного человека и найденная информация на просторах интернета. После выхода проекта в массы - предоставление дополнительной информации, от замих заказчиков, поможет улучшить качество модели и сократить мошеннические операции

### 1.1.1 Оценка рисков и план действий

*   **Не уложиться в сроки.**
    *   *Риск:* Задержка с feature engineering, непредвиденные трудности с обучением модели, сложности с интеграцией.
    *   *Варианты рещения:*
        *   Четкое определение этапов проекта и сроков
        *   Резервирование времени на непредвиденные обстоятельства
        *   Изучение алгоритмов других разработчиков в открытых источниках
*   **Малое количество или плохое качество данных, которые не позволят получить эффективную модель.**
    *   *Риск:* Выбранные датасеты могут иметь достаточного количества мошеннических транзакций в обучающем наборе, наличие пропусков в данных, ошибки в данных.
    *   *Варианты рещения:*
        *   Проведение EDA для выявления проблем с данными.
        *   Использование методов обработки пропущенных значений
        *   Использование методов балансировки данных, если данные сильно несбалансированы
        *   Рассмотрение возможности использования синтетических данных, на примере датасета Synthetic Financial Datasets For Fraud Detection
*   **Данные качественные, но закономерности в принципе отсутствуют и, как следствие, полученные результаты не интересны заказчику.**
    *   На момент разработки этого решения заказкича нет, таким образом можно исключить данный пункт

### 1.2 Решаемые задачи с точки зрения аналитики (Data Mining goals)

*   **Какую метрику мы будем использовать для оценки результата моделирования**

    *   **Основная метрика:** AUC-ROC,  Необходима, чтобы хорошо ранжировать транзакции по степени подозрительности,  учитывая несбалансированность данных
    *   **Дополнительные метрики:** Precision, Recall, F1-score. Эти метрики будут использованны для детальной оценки работы модели

*   **Каков критерий успешности модели?**

    *   **Минимальный порог (для начала):** AUC-ROC = 0.65. Это показывает, что модель лучше случайного предсказания.
    *   **Целевой порог (оптимальный):** AUC-ROC >= 0.75. Более высокая оценка, что позволит более эффективно обнаруживать мошенничество.
    *   **Дополнительно:**  Необходимо оценить баланс между Precision и Recall. Высокий Recall более важен, чем высокая Precision, так будет меньше пропущенных мошеннических транзакций
*   **Если объективный критерий качества использовать не будем, то как будут оцениваться результаты?**
    *   В данном проекте мы будем отталкиваться, что объективные критерии качества будут использоваться с учётом метрик AUC-ROC, Precision, Recall, F1-score

### 1.3 План проекта (Project Plan)

*   **Неделя 1: Бизнес-анализ (Business Understanding)**
    *   Бизнес-анализ: Определение целей, задач, сбор требований, выявление участников проекта (этот пункт внесён для дальнейшего распространения в массы) и создание каналов коммуникации.
    *   Начальный анализ данных: Выявление доступных источников данных, запрос доступа (если он потребуется) и первичное ознакомление со структурой данных.

*   **Неделя 2: Анализ данных (Data Understanding)**
    *   Анализ данных (EDA): Разведочный анализ данных, выявление пропусков, выбросов, распределений и корреляций. Определение целевой переменной
    *   Подготовка данных: Определение стратегии обработки пропусков, обработка категориальных признаков (one-hot encoding или другие методы), возможно переиспользование алгоритмов из открытых источников

*   **Неделя 3: Подготовка данных (Data Preparation)**
    *   Очистка данных: Удаление дубликатов, обработка ошибок
    *   Feature Engineering: Создание новых признаков, агрегация, трансформации
    *   Масштабирование признаков: StandardScaler, MinMaxScaler
    *   Разделение данных: Разделение данных на обучающую и тестовую выборки (этот пункт можно убрать, так как это очевидно, но для потенциального заказчика - скорее всего интересный)

*   **Недели 4-5: Моделирование (Modeling)**
    *   Выбор алгоритмов: Определение списка алгоритмов для экспериментов (логистическая регрессия, random forest, catboost, isolation forest или графовая модель)
    *   Обучение моделей: Обучение моделей на обучающей выборке
    *   Настройка гиперпараметров: GridSearchCV, RandomizedSearchCV
    *   Обработка несбалансированности данных: SMOTE, перевзвешивание

*   **Неделя 6: Оценка результата (Evaluation)**
    *   Оценка моделей: Оценка производительности моделей на тестовой выборке (AUC-ROC, Precision, Recall, F1-score). Выбор лучшей модели
    *   Анализ ошибок: Выявление ложных срабатываний
    *   Интерпретация результатов: Оценка важности признаков (feature importance)

*   **Недели 7-8: Внедрение (Deployment)**
    *   Базовое внедрение: Создание простого API (в данном проекте будет использован FastAPI), для предсказания вероятности мошенничества на основе входных данных.
    *   Развертывание API: Развертывание API будет производиться через docker контейнер
    *   Тестирование: Тестирование API для проверки работоспособности